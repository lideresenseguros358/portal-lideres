/**
 * DIAGNOSTIC: Vertex AI Chat Test
 * ================================
 * Standalone test to verify Vertex AI connectivity for chat.
 * Uses the EXACT same auth pattern as the working email classifier.
 * 
 * GET  /api/diagnostics/vertex-chat          ‚Äî run all tests
 * POST /api/diagnostics/vertex-chat          ‚Äî test with custom message
 */

export const dynamic = 'force-dynamic';
export const runtime = 'nodejs';

import { NextRequest, NextResponse } from 'next/server';
import { GoogleAuth } from 'google-auth-library';

function json(data: any, status = 200) {
  return NextResponse.json(data, { status });
}

// ‚îÄ‚îÄ Test 1: Env vars present ‚îÄ‚îÄ
function testEnvVars() {
  const vars = {
    GOOGLE_APPLICATION_CREDENTIALS_JSON: !!process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON,
    GOOGLE_CLOUD_PROJECT_ID: process.env.GOOGLE_CLOUD_PROJECT_ID || '(not set)',
    GOOGLE_CLOUD_LOCATION: process.env.GOOGLE_CLOUD_LOCATION || '(not set ‚Äî will default to us-central1)',
    VERTEX_MODEL_CHAT: process.env.VERTEX_MODEL_CHAT || '(not set ‚Äî will default to gemini-1.5-flash)',
    VERTEX_MODEL_EMAIL: process.env.VERTEX_MODEL_EMAIL || '(not set)',
    VERTEX_API_KEY: process.env.VERTEX_API_KEY ? 'SET (first 10: ' + process.env.VERTEX_API_KEY.substring(0, 10) + '...)' : '(not set)',
  };

  let credentialsParsed = false;
  let credentialsType = '';
  let credentialsProjectId = '';
  let credentialsClientEmail = '';
  try {
    const creds = JSON.parse(process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON || '{}');
    credentialsParsed = true;
    credentialsType = creds.type || '(no type)';
    credentialsProjectId = creds.project_id || '(no project_id)';
    credentialsClientEmail = creds.client_email || '(no client_email)';
  } catch {
    credentialsParsed = false;
  }

  return {
    test: 'env_vars',
    pass: !!process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON && !!process.env.GOOGLE_CLOUD_PROJECT_ID,
    vars,
    credentials: {
      parseable: credentialsParsed,
      type: credentialsType,
      project_id: credentialsProjectId,
      client_email: credentialsClientEmail,
    },
  };
}

// ‚îÄ‚îÄ Test 2: Auth client creation ‚îÄ‚îÄ
async function testAuthClient() {
  try {
    const credentialsJson = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;
    if (!credentialsJson) return { test: 'auth_client', pass: false, error: 'No credentials JSON' };

    const credentials = JSON.parse(credentialsJson);
    const auth = new GoogleAuth({
      credentials,
      scopes: ['https://www.googleapis.com/auth/cloud-platform'],
    });

    const client = await auth.getClient();
    const tokenResponse = await client.getAccessToken();
    const hasToken = !!tokenResponse?.token;

    return {
      test: 'auth_client',
      pass: hasToken,
      tokenPrefix: hasToken ? tokenResponse.token!.substring(0, 20) + '...' : null,
    };
  } catch (err: any) {
    return { test: 'auth_client', pass: false, error: err.message, stack: err.stack?.substring(0, 200) };
  }
}

// ‚îÄ‚îÄ Test 3: Simple Vertex AI call (same pattern as working email classifier) ‚îÄ‚îÄ
async function testVertexSimple() {
  try {
    const credentialsJson = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON!;
    const credentials = JSON.parse(credentialsJson);
    const auth = new GoogleAuth({
      credentials,
      scopes: ['https://www.googleapis.com/auth/cloud-platform'],
    });
    const client = await auth.getClient();

    const projectId = process.env.GOOGLE_CLOUD_PROJECT_ID!;
    const location = process.env.GOOGLE_CLOUD_LOCATION || 'us-central1';
    const model = process.env.VERTEX_MODEL_CHAT || 'gemini-1.5-flash';

    // EXACT same pattern as working email classifier ‚Äî no systemInstruction
    const endpoint = `https://${location}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${location}/publishers/google/models/${model}:generateContent`;

    const requestBody = {
      contents: [
        {
          role: 'user',
          parts: [{ text: 'Responde en una oraci√≥n corta: ¬øQu√© es un seguro de auto?' }],
        },
      ],
      generationConfig: {
        temperature: 0.3,
        topP: 0.8,
        topK: 10,
        maxOutputTokens: 256,
      },
    };

    console.log('[VERTEX-TEST] Calling:', endpoint);
    const start = Date.now();

    const response = await client.request({
      url: endpoint,
      method: 'POST',
      data: requestBody,
    });

    const elapsed = Date.now() - start;
    const data: any = response.data;
    const reply = data?.candidates?.[0]?.content?.parts?.[0]?.text || '(no text in response)';
    const tokensUsed = data?.usageMetadata?.totalTokenCount || 0;

    return {
      test: 'vertex_simple_call',
      pass: true,
      reply,
      tokensUsed,
      elapsedMs: elapsed,
      endpoint,
      model,
    };
  } catch (err: any) {
    return {
      test: 'vertex_simple_call',
      pass: false,
      error: err.message,
      status: err.response?.status,
      statusText: err.response?.statusText,
      responseData: JSON.stringify(err.response?.data)?.substring(0, 500),
      code: err.code,
    };
  }
}

// ‚îÄ‚îÄ Test 4: Vertex AI with systemInstruction (Gemini 1.5+ feature) ‚îÄ‚îÄ
async function testVertexWithSystemInstruction() {
  try {
    const credentialsJson = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON!;
    const credentials = JSON.parse(credentialsJson);
    const auth = new GoogleAuth({
      credentials,
      scopes: ['https://www.googleapis.com/auth/cloud-platform'],
    });
    const client = await auth.getClient();

    const projectId = process.env.GOOGLE_CLOUD_PROJECT_ID!;
    const location = process.env.GOOGLE_CLOUD_LOCATION || 'us-central1';
    const model = process.env.VERTEX_MODEL_CHAT || 'gemini-1.5-flash';

    const endpoint = `https://${location}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${location}/publishers/google/models/${model}:generateContent`;

    const requestBody = {
      systemInstruction: {
        parts: [{ text: 'Eres Lissa, una asistente virtual amigable de una corredur√≠a de seguros en Panam√°. Hablas en espa√±ol, eres c√°lida y cercana. Usas "t√∫" y emojis moderados.' }],
      },
      contents: [
        {
          role: 'user',
          parts: [{ text: 'Hola, quiero saber sobre seguros de auto' }],
        },
      ],
      generationConfig: {
        temperature: 0.7,
        topP: 0.9,
        topK: 40,
        maxOutputTokens: 512,
      },
    };

    const start = Date.now();
    const response = await client.request({
      url: endpoint,
      method: 'POST',
      data: requestBody,
    });

    const elapsed = Date.now() - start;
    const data: any = response.data;
    const reply = data?.candidates?.[0]?.content?.parts?.[0]?.text || '(no text)';
    const tokensUsed = data?.usageMetadata?.totalTokenCount || 0;

    return {
      test: 'vertex_with_system_instruction',
      pass: true,
      reply,
      tokensUsed,
      elapsedMs: elapsed,
    };
  } catch (err: any) {
    return {
      test: 'vertex_with_system_instruction',
      pass: false,
      error: err.message,
      status: err.response?.status,
      responseData: JSON.stringify(err.response?.data)?.substring(0, 500),
    };
  }
}

// ‚îÄ‚îÄ Test 5: Full Lissa chat simulation ‚îÄ‚îÄ
async function testLissaChat(userMessage: string) {
  try {
    const credentialsJson = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON!;
    const credentials = JSON.parse(credentialsJson);
    const auth = new GoogleAuth({
      credentials,
      scopes: ['https://www.googleapis.com/auth/cloud-platform'],
    });
    const client = await auth.getClient();

    const projectId = process.env.GOOGLE_CLOUD_PROJECT_ID!;
    const location = process.env.GOOGLE_CLOUD_LOCATION || 'us-central1';
    const model = process.env.VERTEX_MODEL_CHAT || 'gemini-1.5-flash';

    const endpoint = `https://${location}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${location}/publishers/google/models/${model}:generateContent`;

    const systemPrompt = `Eres Lissa, la asistente virtual de L√≠deres en Seguros, una corredur√≠a de seguros en Panam√°. Hablas como una persona real: c√°lida, emp√°tica, cercana. Usas "t√∫" y un tono conversacional natural, como si fueras una amiga que sabe mucho de seguros.

Tu personalidad:
- Eres genuinamente amable y te importa ayudar
- Usas emojis de forma natural pero sin exagerar (üíö üëã üòä üìã)
- Haces preguntas de seguimiento para entender mejor
- Muestras inter√©s real en lo que la persona necesita
- NUNCA suenas como un robot ni repites plantillas

Reglas:
1. Siempre en espa√±ol
2. No inventas coberturas ni detalles de p√≥lizas
3. Para cotizar, diriges a: https://portal.lideresenseguros.com/cotizadores
4. Si no puedes resolver algo, ofreces: contacto@lideresenseguros.com o 223-2373`;

    const requestBody = {
      systemInstruction: {
        parts: [{ text: systemPrompt }],
      },
      contents: [
        {
          role: 'user',
          parts: [{ text: userMessage }],
        },
      ],
      generationConfig: {
        temperature: 0.7,
        topP: 0.9,
        topK: 40,
        maxOutputTokens: 1024,
      },
    };

    const start = Date.now();
    const response = await client.request({
      url: endpoint,
      method: 'POST',
      data: requestBody,
    });

    const elapsed = Date.now() - start;
    const data: any = response.data;
    const reply = data?.candidates?.[0]?.content?.parts?.[0]?.text || '(no text)';
    const tokensUsed = data?.usageMetadata?.totalTokenCount || 0;
    const finishReason = data?.candidates?.[0]?.finishReason || 'unknown';

    return {
      test: 'lissa_chat',
      pass: true,
      userMessage,
      reply,
      tokensUsed,
      elapsedMs: elapsed,
      finishReason,
    };
  } catch (err: any) {
    return {
      test: 'lissa_chat',
      pass: false,
      userMessage,
      error: err.message,
      status: err.response?.status,
      responseData: JSON.stringify(err.response?.data)?.substring(0, 500),
    };
  }
}

// ‚îÄ‚îÄ Test: Model discovery via Vertex AI (service account) ‚îÄ‚îÄ
async function testVertexModels() {
  const models = ['gemini-1.5-flash', 'gemini-1.5-flash-001', 'gemini-1.5-flash-002', 'gemini-1.5-pro', 'gemini-1.0-pro', 'gemini-pro', 'gemini-2.0-flash', 'gemini-2.0-flash-001'];

  const credentialsJson = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON!;
  const credentials = JSON.parse(credentialsJson);
  const auth = new GoogleAuth({ credentials, scopes: ['https://www.googleapis.com/auth/cloud-platform'] });
  const client = await auth.getClient();
  const projectId = process.env.GOOGLE_CLOUD_PROJECT_ID!;
  const location = process.env.GOOGLE_CLOUD_LOCATION || 'us-central1';

  const results: any[] = [];
  for (const model of models) {
    const endpoint = `https://${location}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${location}/publishers/google/models/${model}:generateContent`;
    try {
      const start = Date.now();
      const res = await client.request({ url: endpoint, method: 'POST', data: { contents: [{ role: 'user', parts: [{ text: 'Di solo: OK' }] }], generationConfig: { temperature: 0, maxOutputTokens: 10 } } });
      const reply = (res.data as any)?.candidates?.[0]?.content?.parts?.[0]?.text || '';
      results.push({ model, api: 'vertex', status: '‚úÖ', reply: reply.trim(), ms: Date.now() - start });
    } catch (err: any) {
      results.push({ model, api: 'vertex', status: '‚ùå', error: err.response?.status || err.message });
    }
  }
  return results;
}

// ‚îÄ‚îÄ Test: Model discovery via Gemini API (API key) ‚îÄ‚îÄ
async function testGeminiApiModels() {
  const apiKey = process.env.VERTEX_API_KEY;
  if (!apiKey) return [{ api: 'gemini_api', status: '‚ùå', error: 'No VERTEX_API_KEY set' }];

  const models = ['gemini-1.5-flash', 'gemini-1.5-flash-latest', 'gemini-1.5-pro', 'gemini-1.5-pro-latest', 'gemini-pro', 'gemini-2.0-flash', 'gemini-2.0-flash-exp', 'gemini-2.5-flash-preview-04-17', 'gemini-2.5-pro-preview-03-25'];

  const results: any[] = [];
  for (const model of models) {
    const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;
    try {
      const start = Date.now();
      const res = await fetch(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ contents: [{ parts: [{ text: 'Di solo: OK' }] }], generationConfig: { temperature: 0, maxOutputTokens: 10 } }),
      });
      const data = await res.json();
      if (!res.ok) {
        results.push({ model, api: 'gemini_api', status: '‚ùå', error: res.status, detail: (data as any)?.error?.message?.substring(0, 100) });
      } else {
        const reply = (data as any)?.candidates?.[0]?.content?.parts?.[0]?.text || '';
        results.push({ model, api: 'gemini_api', status: '‚úÖ', reply: reply.trim(), ms: Date.now() - start });
      }
    } catch (err: any) {
      results.push({ model, api: 'gemini_api', status: '‚ùå', error: err.message });
    }
  }
  return results;
}

// ‚îÄ‚îÄ Full Lissa test using Gemini API with API key ‚îÄ‚îÄ
async function testLissaGeminiApi(userMessage: string, model: string) {
  const apiKey = process.env.VERTEX_API_KEY;
  if (!apiKey) return { test: 'lissa_gemini_api', pass: false, error: 'No API key' };

  const systemPrompt = `Eres Lissa, la asistente virtual de L√≠deres en Seguros en Panam√°. Hablas como una persona real: c√°lida, emp√°tica, cercana. Usas "t√∫" y un tono conversacional. Usas emojis moderados. Siempre en espa√±ol. Para cotizar: https://portal.lideresenseguros.com/cotizadores. Contacto: contacto@lideresenseguros.com o 223-2373.`;

  const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;
  try {
    const start = Date.now();
    const res = await fetch(url, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        systemInstruction: { parts: [{ text: systemPrompt }] },
        contents: [{ parts: [{ text: userMessage }] }],
        generationConfig: { temperature: 0.7, topP: 0.9, maxOutputTokens: 1024 },
      }),
    });
    const data: any = await res.json();
    if (!res.ok) return { test: 'lissa_gemini_api', pass: false, model, userMessage, error: data?.error?.message };
    const reply = data?.candidates?.[0]?.content?.parts?.[0]?.text || '(empty)';
    return { test: 'lissa_gemini_api', pass: true, model, userMessage, reply, ms: Date.now() - start };
  } catch (err: any) {
    return { test: 'lissa_gemini_api', pass: false, model, userMessage, error: err.message };
  }
}

// ‚îÄ‚îÄ GET handler ‚Äî run all tests ‚îÄ‚îÄ
export async function GET() {
  console.log('[VERTEX-TEST] Running diagnostic tests...');
  const results: any[] = [];

  // 1. Env vars
  results.push(testEnvVars());

  // 2. Auth client
  results.push(await testAuthClient());

  // 3. Vertex AI models (service account)
  const vertexModels = await testVertexModels();
  results.push({ test: 'vertex_ai_models', details: vertexModels });

  // 4. Gemini API models (API key)
  const geminiModels = await testGeminiApiModels();
  results.push({ test: 'gemini_api_models', details: geminiModels });

  // Find best working approach
  const workingVertex = vertexModels.find((r: any) => r.status === '‚úÖ');
  const workingGemini = geminiModels.find((r: any) => r.status === '‚úÖ');

  let bestApi = '';
  let bestModel = '';

  if (workingGemini) {
    bestApi = 'gemini_api';
    bestModel = workingGemini.model;
  } else if (workingVertex) {
    bestApi = 'vertex';
    bestModel = workingVertex.model;
  }

  // 5. Full Lissa tests with the working model
  if (bestModel) {
    const testMsgs = [
      'Hola, buenos d√≠as',
      'Qu√© significa deducible?',
      'Quiero cotizar un seguro de auto, c√≥mo hago?',
      'Tengo una duda sobre mi cobertura de salud',
      'Tengo un problema con mi pago y nadie me ayuda',
    ];

    if (bestApi === 'gemini_api') {
      for (const msg of testMsgs) {
        results.push(await testLissaGeminiApi(msg, bestModel));
      }
    } else {
      const orig = process.env.VERTEX_MODEL_CHAT;
      process.env.VERTEX_MODEL_CHAT = bestModel;
      for (const msg of testMsgs) {
        results.push(await testLissaChat(msg));
      }
      process.env.VERTEX_MODEL_CHAT = orig;
    }
  } else {
    results.push({ test: 'lissa_tests', pass: false, error: 'No working model found via either API' });
  }

  return json({
    summary: bestModel ? `‚úÖ FOUND WORKING MODEL: ${bestModel} via ${bestApi}` : '‚ùå NO WORKING MODEL FOUND',
    timestamp: new Date().toISOString(),
    recommendation: bestModel ? { api: bestApi, model: bestModel, action: bestApi === 'gemini_api' ? 'Switch chat code to use Gemini API with VERTEX_API_KEY' : `Set VERTEX_MODEL_CHAT=${bestModel}` } : { action: 'Enable Vertex AI Generative AI API in GCP console, or get a valid Gemini API key' },
    results,
  });
}

// ‚îÄ‚îÄ POST handler ‚Äî test with custom message ‚îÄ‚îÄ
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const message = body.message || 'Hola, ¬øqu√© servicios ofrecen?';
    const result = await testLissaChat(message);
    return json(result);
  } catch (err: any) {
    return json({ error: err.message }, 500);
  }
}
